# TODO: complete this file.
# Classifier generation:
# Let N be the size of the training set.
# for each of t iterations:
    # sample N instances with replacement from the original training set.
    # apply the learning algorithm to the sample.
    # store the resulting classifier.

# Classification:
# for each of the t classifiers:
#    predict class of instance using classifier.
# return class that was predicted most often.

import numpy as np
from sklearn.impute import KNNImputer
from utils import *


def ensemble (train_matrix,test_data):

    # create a list to store all the probabilities generated by 3 base models
    prob_all = []
    # build 3 classifiers
    for n in range(3):
        # random sampling the train data
        # randomly generate the row indices
        rand_mat_idx = np.random.randint(train_matrix.shape[0], size=train_matrix.shape[0])
        # reconstruct a train data matrix based on the row indices
        resample_mat = train_matrix[rand_mat_idx, :]
        # create a KNN model with number of neighbors = k
        k =16
        nbrs = KNNImputer(n_neighbors=k)
        # fit and transform the KNN model using the randomly sampled train data matrix
        mat = nbrs.fit_transform(resample_mat.toarray())
        # create a list to store the predictions for each model

    #########

        # average probability of 3 model outputs
    #     predictions = []
    #     for i in range(len(test_data["user_id"])):
    #         cur_user_id = test_data["user_id"][i]
    #         cur_question_id = test_data["question_id"][i]
    #         predictions.append(mat[cur_user_id, cur_question_id])
    #     # store the prediction of each model into a list
    #     prob_all.append(predictions)
    # prob_all = np.asarray(prob_all)

    # # average the probability computed by the 3 models
    # prob_avg = np.mean(prob_all, axis=0)
    # pred = []
    # threshold = 0.5
    # total_accurate = 0
    # # classify the data and compute the accuracy
    # for i in range(len(prob_avg)):
    #     if prob_avg[i] < threshold:
    #         pred.append(0)
    #         if test_data['is_correct'][i]:
    #             total_accurate += 0
    #         else:
    #             total_accurate += 1
    #     else:
    #         pred.append(1)
    #         if test_data['is_correct'][i]:
    #             total_accurate += 1
    #         else:
    #             total_accurate += 0
    # acc = total_accurate / float(len(prob_avg))
    ##################

    # average binary outputs of three models
        # create a list to store the predictions for each model
        predictions = []
        threshold = 0.5
        total_accurate = 0
        for i in range(len(test_data["user_id"])):
            cur_user_id = test_data["user_id"][i]
            cur_question_id = test_data["question_id"][i]
            if mat[cur_user_id, cur_question_id] >= threshold:
                predictions.append(1)
            else:
                predictions.append(0)
        # store the prediction of each model into a list
        prob_all.append(predictions)
    prob_all = np.asarray(prob_all)
    prob_avg = np.mean(prob_all, axis=0)
    for i in range (len(prob_avg)):
        if prob_avg[i] >= threshold and test_data['is_correct'][i]:
            total_accurate += 1
        if prob_avg[i] < threshold and not test_data['is_correct'][i]:
            total_accurate += 1
    acc = total_accurate / float(len(prob_avg))
    return acc

if __name__ == '__main__':
    train_data = load_train_csv("../data")
    sparse_matrix = load_train_sparse("../data")
    val_data = load_valid_csv("../data")
    test_data = load_public_test_csv("../data")
    val_acc = ensemble (sparse_matrix, val_data)
    test_acc = ensemble (sparse_matrix, test_data)


